#!/usr/bin/env python3
"""
Klingæ•°æ® - SIDé¢„æµ‹è®­ç»ƒæ•°æ®ç”Ÿæˆè„šæœ¬

ç”¨é€”: Stage 2 è®­ç»ƒ - Sequential Recommendation
è®­ç»ƒæ¨¡å‹æ ¹æ®ç”¨æˆ·å†å²è¡Œä¸ºé¢„æµ‹ä¸‹ä¸€ä¸ªç‰©å“çš„SID

è¾“å…¥:
  - kling_items.json (ç‰©å“å…ƒæ•°æ®, 4ç»´SID)
  - kling_sequential.txt (ç”¨æˆ·åºåˆ—)

è¾“å‡º:
  - training_prediction_sid_data_kling_train.parquet
  - training_prediction_sid_data_kling_val.parquet
  - training_prediction_sid_data_kling_test.parquet

æ•°æ®æ ¼å¼:
  {
      'user_id': '123',
      'description': 'The user has purchased the following items: <|sid_begin|>...<|sid_end|>; ...',
      'groundtruth': '<|sid_begin|><s_a_X><s_b_X><s_c_X><s_d_X><|sid_end|>'
  }

è®­ç»ƒæ—¶ä¼šè¢«è½¬æ¢ä¸ºChatæ ¼å¼:
  <|im_start|>system
  You are a professional recommendation expert...<|im_end|>
  <|im_start|>user
  {description}<|im_end|>
  <|im_start|>assistant
  <think>
  
  </think>
  {groundtruth}<|im_end|>
"""

from __future__ import annotations

import json
from pathlib import Path

import pandas as pd


def load_items(items_file: Path) -> dict:
    """åŠ è½½ç‰©å“å…ƒæ•°æ®"""
    print(f"ğŸ“– åŠ è½½ç‰©å“å…ƒæ•°æ®: {items_file}")
    with items_file.open("r", encoding="utf-8") as f:
        items = json.load(f)
    print(f"   âœ… åŠ è½½äº† {len(items)} ä¸ªç‰©å“")
    
    # éªŒè¯SIDæ ¼å¼
    sample_item = list(items.values())[0]
    sample_sid = sample_item['sid']
    has_4_dims = all(f'<s_{dim}_' in sample_sid for dim in ['a', 'b', 'c', 'd'])
    if not has_4_dims:
        print(f"   âš ï¸  è­¦å‘Š: SIDæ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼ˆåº”è¯¥æ˜¯4ç»´ï¼‰")
        print(f"   ç¤ºä¾‹: {sample_sid}")
    else:
        print(f"   âœ… SIDæ ¼å¼éªŒè¯é€šè¿‡ï¼ˆ4ç»´ï¼‰")
    
    return items


def extract_sid_sequence(item_ids: list[str], user_id: str, items: dict) -> list[str]:
    """ä»item_idsä¸­æå–SIDåºåˆ—"""
    sid_sequence: list[str] = []
    for item_id in item_ids:
        item_info = items.get(item_id)
        if not item_info:
            # print(f"âš ï¸  è­¦å‘Š: user {user_id} çš„ item_id {item_id} æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
            continue
        sid = item_info.get("sid")
        if not sid:
            # print(f"âš ï¸  è­¦å‘Š: user {user_id} çš„ item_id {item_id} ç¼ºå°‘sidå­—æ®µï¼Œè·³è¿‡")
            continue
        sid_sequence.append(sid)
    return sid_sequence


def build_dataset_entry(
    user_id: str,
    sid_sequence: list[str],
    tail_remove_count: int,
) -> dict | None:
    """
    æ„å»ºä¸€æ¡è®­ç»ƒæ•°æ®
    
    Args:
        user_id: ç”¨æˆ·ID
        sid_sequence: ç”¨æˆ·çš„SIDåºåˆ—
        tail_remove_count: ä»å°¾éƒ¨ç§»é™¤çš„itemæ•°é‡ï¼ˆç”¨äºtrain/val/teståˆ’åˆ†ï¼‰
    
    Returns:
        {
            'user_id': '123',
            'description': 'ç”¨æˆ·å†å²çš„SIDåˆ—è¡¨',
            'groundtruth': 'è¦é¢„æµ‹çš„ä¸‹ä¸€ä¸ªSID'
        }
    """
    # ç¡®ä¿åºåˆ—é•¿åº¦è¶³å¤Ÿ
    if len(sid_sequence) <= tail_remove_count + 1:
        return None

    # æˆªå–å€™é€‰åºåˆ—
    candidate_sequence = (
        sid_sequence[: len(sid_sequence) - tail_remove_count]
        if tail_remove_count > 0
        else sid_sequence
    )

    # è‡³å°‘éœ€è¦2ä¸ªitemï¼ˆ1ä¸ªå†å² + 1ä¸ªé¢„æµ‹ï¼‰
    if len(candidate_sequence) < 2:
        return None

    # æœ€åä¸€ä¸ªä½œä¸ºgroundtruthï¼Œå…¶ä½™ä½œä¸ºå†å²
    groundtruth = candidate_sequence[-1]
    description_sids = candidate_sequence[:-1]

    if not description_sids:
        return None

    # æ„é€ æè¿°æ–‡æœ¬
    description = "The user has purchased the following items: " + "; ".join(description_sids) + ";"
    
    return {
        "user_id": user_id,
        "description": description,
        "groundtruth": groundtruth,
    }


def generate_sid_prediction_data(
    sequential_file: Path,
    items_file: Path,
    output_train: Path,
    output_val: Path,
    output_test: Path,
) -> None:
    """ç”ŸæˆSIDé¢„æµ‹è®­ç»ƒæ•°æ®"""
    
    print("="*60)
    print("ğŸ¯ ç”ŸæˆKling SIDé¢„æµ‹è®­ç»ƒæ•°æ® (Stage 2)")
    print("="*60)
    print()
    
    # åŠ è½½ç‰©å“å…ƒæ•°æ®
    items = load_items(items_file)

    # åŠ è½½ç”¨æˆ·åºåˆ—
    print(f"\nğŸ“– åŠ è½½ç”¨æˆ·åºåˆ—: {sequential_file}")
    with sequential_file.open("r", encoding="utf-8") as f:
        lines = f.readlines()
    print(f"   âœ… åŠ è½½äº† {len(lines)} ä¸ªç”¨æˆ·åºåˆ—")

    train_rows: list[dict] = []
    val_rows: list[dict] = []
    test_rows: list[dict] = []
    
    skipped_users = 0

    print(f"\nğŸ”„ å¤„ç†ç”¨æˆ·åºåˆ—...")
    for idx, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue

        elements = line.split()
        if len(elements) <= 1:
            continue

        user_id = elements[0]
        item_ids = elements[1:]

        # æå–SIDåºåˆ—
        sid_sequence = extract_sid_sequence(item_ids, user_id, items)
        if len(sid_sequence) == 0:
            skipped_users += 1
            continue

        # Trainé›†: å»æ‰æœ€å2ä¸ªitem
        entry_train = build_dataset_entry(user_id, sid_sequence, tail_remove_count=2)
        if entry_train:
            train_rows.append(entry_train)

        # Valé›†: å»æ‰æœ€å1ä¸ªitem
        entry_val = build_dataset_entry(user_id, sid_sequence, tail_remove_count=1)
        if entry_val:
            val_rows.append(entry_val)

        # Testé›†: ä½¿ç”¨å®Œæ•´åºåˆ—
        entry_test = build_dataset_entry(user_id, sid_sequence, tail_remove_count=0)
        if entry_test:
            test_rows.append(entry_test)

        if (idx + 1) % 1000 == 0:
            print(f"   å·²å¤„ç† {idx + 1}/{len(lines)} ä¸ªç”¨æˆ·...")

    print(f"   âœ… å®Œæˆå¤„ç†")
    print(f"   âš ï¸  è·³è¿‡çš„ç”¨æˆ·ï¼ˆæ— æœ‰æ•ˆSIDï¼‰: {skipped_users}")

    # åˆ›å»ºDataFrame
    print(f"\nğŸ“Š åˆ›å»ºDataFrame...")
    df_train = pd.DataFrame(train_rows)
    df_val = pd.DataFrame(val_rows)
    df_test = pd.DataFrame(test_rows)

    print(f"   Trainé›†: {len(df_train)} æ¡")
    print(f"   Valé›†:   {len(df_val)} æ¡")
    print(f"   Testé›†:  {len(df_test)} æ¡")

    # ä¿å­˜parquetæ–‡ä»¶
    print(f"\nğŸ’¾ ä¿å­˜parquetæ–‡ä»¶...")
    
    print(f"   ä¿å­˜Trainé›†: {output_train}")
    df_train.to_parquet(output_train, engine="pyarrow", index=False)

    print(f"   ä¿å­˜Valé›†: {output_val}")
    df_val.to_parquet(output_val, engine="pyarrow", index=False)

    print(f"   ä¿å­˜Testé›†: {output_test}")
    df_test.to_parquet(output_test, engine="pyarrow", index=False)

    # æ˜¾ç¤ºç¤ºä¾‹
    def preview(df: pd.DataFrame, name: str) -> None:
        print(f"\nğŸ“ {name} æ•°æ®ç¤ºä¾‹ (å‰2æ¡):")
        for i, row in df.head(2).iterrows():
            print(f"\n   [{i+1}] User: {row['user_id']}")
            desc = row['description']
            if len(desc) > 150:
                print(f"       Description: {desc[:150]}...")
            else:
                print(f"       Description: {desc}")
            print(f"       Groundtruth: {row['groundtruth']}")

    preview(df_train, "Trainé›†")
    preview(df_val, "Valé›†")
    preview(df_test, "Testé›†")
    
    print(f"\n{'='*60}")
    print(f"âœ… SIDé¢„æµ‹è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ!")
    print(f"{'='*60}")
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print(f"   è¿è¡Œè®­ç»ƒè„šæœ¬: train/run_training_stage2.sh")
    print(f"   æˆ–ä½¿ç”¨: train/scripts/train_beauty_sid_rec.py\n")


if __name__ == "__main__":
    # é»˜è®¤è·¯å¾„ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    sequential_file = Path("../kling_data/kling_sequential.txt")
    items_file = Path("../kling_data/kling_items.json")
    
    output_train = Path("./training_prediction_sid_data_kling_train.parquet")
    output_val = Path("./training_prediction_sid_data_kling_val.parquet")
    output_test = Path("./training_prediction_sid_data_kling_test.parquet")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not sequential_file.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {sequential_file}")
        print(f"   è¯·å…ˆè¿è¡Œ: kling_data/process_kling_data_fixed.py")
        exit(1)
    
    if not items_file.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {items_file}")
        print(f"   è¯·å…ˆè¿è¡Œ: kling_data/process_kling_data_fixed.py")
        exit(1)

    generate_sid_prediction_data(
        sequential_file=sequential_file,
        items_file=items_file,
        output_train=output_train,
        output_val=output_val,
        output_test=output_test,
    )
