#!/usr/bin/env python3
"""
Klingæ•°æ® - RA (Retrieve & Align) è®­ç»ƒæ•°æ®ç”Ÿæˆè„šæœ¬

ç”¨é€”: ç»“åˆSIDå’Œå¯Œæ–‡æœ¬ä¿¡æ¯çš„è®­ç»ƒæ•°æ®
åŒ…å«SIDã€titleå’Œcategoriesï¼Œç”¨äºæ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡è®­ç»ƒ

è¾“å…¥:
  - kling_items.json (ç‰©å“å…ƒæ•°æ®, 4ç»´SID)
  - kling_sequential.txt (ç”¨æˆ·åºåˆ—)

è¾“å‡º:
  - training_RA_kling_train.parquet
  - training_RA_kling_val.parquet
  - training_RA_kling_test.parquet

æ•°æ®æ ¼å¼:
  {
      'user_id': '123',
      'description': 'The user has purchased the following items: <|sid_begin|>...<|sid_end|>, its title is "...", its categories are "..."; ...',
      'groundtruth': '<|sid_begin|><s_a_X><s_b_X><s_c_X><s_d_X><|sid_end|>',
      'title': 'ä¸‹ä¸€ä¸ªç‰©å“çš„æ ‡é¢˜',
      'categories': 'ä¸‹ä¸€ä¸ªç‰©å“çš„ç±»åˆ«'
  }
"""

from __future__ import annotations

import json
from pathlib import Path

import pandas as pd


def load_items(items_file: Path) -> dict:
    """åŠ è½½ç‰©å“å…ƒæ•°æ®"""
    print(f"ğŸ“– åŠ è½½ç‰©å“å…ƒæ•°æ®: {items_file}")
    with items_file.open("r", encoding="utf-8") as f:
        items = json.load(f)
    print(f"   âœ… åŠ è½½äº† {len(items)} ä¸ªç‰©å“")
    
    # éªŒè¯SIDæ ¼å¼
    sample_item = list(items.values())[0]
    sample_sid = sample_item['sid']
    has_4_dims = all(f'<s_{dim}_' in sample_sid for dim in ['a', 'b', 'c', 'd'])
    if not has_4_dims:
        print(f"   âš ï¸  è­¦å‘Š: SIDæ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼ˆåº”è¯¥æ˜¯4ç»´ï¼‰")
        print(f"   ç¤ºä¾‹: {sample_sid}")
    else:
        print(f"   âœ… SIDæ ¼å¼éªŒè¯é€šè¿‡ï¼ˆ4ç»´ï¼‰")
    
    return items


def extract_item_sequence(item_ids: list[str], user_id: str, items: dict) -> list[dict]:
    """ä»item_idsä¸­æå–å®Œæ•´çš„ç‰©å“ä¿¡æ¯åºåˆ—"""
    item_sequence: list[dict] = []
    for item_id in item_ids:
        item_info = items.get(item_id)
        if not item_info:
            # print(f"âš ï¸  è­¦å‘Š: user {user_id} çš„ item_id {item_id} æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
            continue
        sid = item_info.get("sid")
        if not sid:
            # print(f"âš ï¸  è­¦å‘Š: user {user_id} çš„ item_id {item_id} ç¼ºå°‘sidå­—æ®µï¼Œè·³è¿‡")
            continue

        title = item_info.get("title", "")
        categories = item_info.get("categories", "")

        item_sequence.append({
            "sid": sid,
            "title": title,
            "categories": categories
        })
    return item_sequence


def build_dataset_entry(
    user_id: str,
    item_sequence: list[dict],
    tail_remove_count: int,
) -> dict | None:
    """
    æ„å»ºä¸€æ¡RAè®­ç»ƒæ•°æ®
    
    Args:
        user_id: ç”¨æˆ·ID
        item_sequence: ç”¨æˆ·çš„ç‰©å“åºåˆ—ï¼ˆåŒ…å«sid, title, categoriesï¼‰
        tail_remove_count: ä»å°¾éƒ¨ç§»é™¤çš„itemæ•°é‡ï¼ˆç”¨äºtrain/val/teståˆ’åˆ†ï¼‰
    
    Returns:
        {
            'user_id': '123',
            'description': 'ç”¨æˆ·å†å²çš„å¯Œæ–‡æœ¬æè¿°ï¼ˆSID + title + categoriesï¼‰',
            'groundtruth': 'è¦é¢„æµ‹çš„ä¸‹ä¸€ä¸ªSID',
            'title': 'è¦é¢„æµ‹çš„ç‰©å“æ ‡é¢˜',
            'categories': 'è¦é¢„æµ‹çš„ç‰©å“ç±»åˆ«'
        }
    """
    # ç¡®ä¿åºåˆ—é•¿åº¦è¶³å¤Ÿ
    if len(item_sequence) <= tail_remove_count + 1:
        return None

    # æˆªå–å€™é€‰åºåˆ—
    candidate_sequence = (
        item_sequence[: len(item_sequence) - tail_remove_count]
        if tail_remove_count > 0
        else item_sequence
    )

    # è‡³å°‘éœ€è¦2ä¸ªitemï¼ˆ1ä¸ªå†å² + 1ä¸ªé¢„æµ‹ï¼‰
    if len(candidate_sequence) < 2:
        return None

    # æœ€åä¸€ä¸ªä½œä¸ºgroundtruthï¼Œå…¶ä½™ä½œä¸ºå†å²
    groundtruth_item = candidate_sequence[-1]
    description_items = candidate_sequence[:-1]

    if not description_items:
        return None

    # æ„é€ å¯Œæ–‡æœ¬æè¿°ï¼ˆåŒ…å«SIDã€titleã€categoriesï¼‰
    item_descriptions = []
    for item in description_items:
        sid = item["sid"]
        title = item["title"]
        categories = item["categories"]

        item_desc = f'{sid}, its title is "{title}", its categories are "{categories}"'
        item_descriptions.append(item_desc)

    description = "The user has purchased the following items: " + "; ".join(item_descriptions) + ";"

    return {
        "user_id": user_id,
        "description": description,
        "groundtruth": groundtruth_item["sid"],
        "title": groundtruth_item["title"],
        "categories": groundtruth_item["categories"],
    }


def generate_RA_data(
    sequential_file: Path,
    items_file: Path,
    output_train: Path,
    output_val: Path,
    output_test: Path,
) -> None:
    """ç”ŸæˆRAè®­ç»ƒæ•°æ®"""
    
    print("="*60)
    print("ğŸ¯ ç”ŸæˆKling RAè®­ç»ƒæ•°æ® (Retrieve & Align)")
    print("="*60)
    print()
    
    # åŠ è½½ç‰©å“å…ƒæ•°æ®
    items = load_items(items_file)

    # åŠ è½½ç”¨æˆ·åºåˆ—
    print(f"\nğŸ“– åŠ è½½ç”¨æˆ·åºåˆ—: {sequential_file}")
    with sequential_file.open("r", encoding="utf-8") as f:
        lines = f.readlines()
    print(f"   âœ… åŠ è½½äº† {len(lines)} ä¸ªç”¨æˆ·åºåˆ—")

    train_rows: list[dict] = []
    val_rows: list[dict] = []
    test_rows: list[dict] = []
    
    skipped_users = 0

    print(f"\nğŸ”„ å¤„ç†ç”¨æˆ·åºåˆ—...")
    for idx, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue

        elements = line.split()
        if len(elements) <= 1:
            continue

        user_id = elements[0]
        item_ids = elements[1:]

        # æå–å®Œæ•´ç‰©å“ä¿¡æ¯åºåˆ—
        item_sequence = extract_item_sequence(item_ids, user_id, items)
        if len(item_sequence) == 0:
            skipped_users += 1
            continue

        # Trainé›†: å»æ‰æœ€å2ä¸ªitem
        entry_train = build_dataset_entry(user_id, item_sequence, tail_remove_count=2)
        if entry_train:
            train_rows.append(entry_train)

        # Valé›†: å»æ‰æœ€å1ä¸ªitem
        entry_val = build_dataset_entry(user_id, item_sequence, tail_remove_count=1)
        if entry_val:
            val_rows.append(entry_val)

        # Testé›†: ä½¿ç”¨å®Œæ•´åºåˆ—
        entry_test = build_dataset_entry(user_id, item_sequence, tail_remove_count=0)
        if entry_test:
            test_rows.append(entry_test)

        if (idx + 1) % 1000 == 0:
            print(f"   å·²å¤„ç† {idx + 1}/{len(lines)} ä¸ªç”¨æˆ·...")

    print(f"   âœ… å®Œæˆå¤„ç†")
    print(f"   âš ï¸  è·³è¿‡çš„ç”¨æˆ·ï¼ˆæ— æœ‰æ•ˆç‰©å“ä¿¡æ¯ï¼‰: {skipped_users}")

    # åˆ›å»ºDataFrame
    print(f"\nğŸ“Š åˆ›å»ºDataFrame...")
    df_train = pd.DataFrame(train_rows)
    df_val = pd.DataFrame(val_rows)
    df_test = pd.DataFrame(test_rows)

    print(f"   Trainé›†: {len(df_train)} æ¡")
    print(f"   Valé›†:   {len(df_val)} æ¡")
    print(f"   Testé›†:  {len(df_test)} æ¡")

    # ä¿å­˜parquetæ–‡ä»¶
    print(f"\nğŸ’¾ ä¿å­˜parquetæ–‡ä»¶...")
    
    print(f"   ä¿å­˜Trainé›†: {output_train}")
    df_train.to_parquet(output_train, engine="pyarrow", index=False)

    print(f"   ä¿å­˜Valé›†: {output_val}")
    df_val.to_parquet(output_val, engine="pyarrow", index=False)

    print(f"   ä¿å­˜Testé›†: {output_test}")
    df_test.to_parquet(output_test, engine="pyarrow", index=False)

    # æ˜¾ç¤ºç¤ºä¾‹
    def preview(df: pd.DataFrame, name: str) -> None:
        print(f"\nğŸ“ {name} æ•°æ®ç¤ºä¾‹ (å‰2æ¡):")
        for i, row in df.head(2).iterrows():
            print(f"\n   [{i+1}] User: {row['user_id']}")
            desc = row['description']
            if len(desc) > 150:
                print(f"       Description: {desc[:150]}...")
            else:
                print(f"       Description: {desc}")
            print(f"       Groundtruth: {row['groundtruth']}")
            print(f"       Title: {row['title'][:50]}..." if len(row['title']) > 50 else f"       Title: {row['title']}")
            print(f"       Categories: {row['categories']}")

    preview(df_train, "Trainé›†")
    preview(df_val, "Valé›†")
    preview(df_test, "Testé›†")
    
    print(f"\n{'='*60}")
    print(f"âœ… RAè®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ!")
    print(f"{'='*60}")
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print(f"   ä½¿ç”¨è®­ç»ƒè„šæœ¬: train/scripts/run_training_RA.sh")
    print(f"   ï¼ˆæ ¹æ®éœ€è¦è°ƒæ•´training_argså‚æ•°ï¼‰\n")


if __name__ == "__main__":
    # é»˜è®¤è·¯å¾„ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    sequential_file = Path("../kling_data/kling_sequential.txt")
    items_file = Path("../kling_data/kling_items.json")
    
    output_train = Path("./training_RA_kling_train.parquet")
    output_val = Path("./training_RA_kling_val.parquet")
    output_test = Path("./training_RA_kling_test.parquet")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not sequential_file.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {sequential_file}")
        print(f"   è¯·å…ˆè¿è¡Œ: kling_data/process_kling_data_fixed.py")
        exit(1)
    
    if not items_file.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {items_file}")
        print(f"   è¯·å…ˆè¿è¡Œ: kling_data/process_kling_data_fixed.py")
        exit(1)

    generate_RA_data(
        sequential_file=sequential_file,
        items_file=items_file,
        output_train=output_train,
        output_val=output_val,
        output_test=output_test,
    )
