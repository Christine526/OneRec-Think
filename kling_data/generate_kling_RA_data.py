#!/usr/bin/env python3
"""
Klingæ•°æ® - Interleaved User Persona Grounding (RA) è®­ç»ƒæ•°æ®ç”Ÿæˆè„šæœ¬

å¯¹åº”è®ºæ–‡é™„å½•A.3.1ä¸­çš„ä»»åŠ¡1ï¼šInterleaved User Persona Grounding
å°†ç”¨æˆ·ç”»åƒä¸ç‰©å“äº¤ç»‡ï¼Œç”Ÿæˆå¯Œæ–‡æœ¬æè¿°ï¼ŒåŒ…å«è¡Œä¸ºç±»å‹ã€æœç´¢è¯ç­‰ä¿¡æ¯

è¾“å…¥æ–‡ä»¶:
- kling_items.json: ç‰©å“å…ƒæ•°æ®
- kling_sequential.txt: ç”¨æˆ·è¡Œä¸ºåºåˆ—  
- kling_user_behaviors.json: ç”¨æˆ·è¡Œä¸ºè¯¦æƒ…

è¾“å‡ºæ–‡ä»¶:
- training_RA_train.parquet
- training_RA_val.parquet
- training_RA_test.parquet
"""

from __future__ import annotations

import json
from pathlib import Path
from collections import defaultdict

import pandas as pd


def get_behavior_description(behavior: dict, item_info: dict) -> str:
    """
    æ ¹æ®Klingæ•°æ®çš„è¡Œä¸ºç±»å‹ç”Ÿæˆå¯Œæ–‡æœ¬æè¿°
    
    Klingæ•°æ®ç»“æ„ï¼š
    - event_type: RECOMMEND/SEARCH/PRODUCE
    - behavior_type: OPERATE/VIDEO_PLAY_FINISH/LONG_PLAY/SHORT_PLAY (PRODUCEåœºæ™¯ä¸‹ä¸ºnull)
    - behavior_subtype: åªæœ‰behavior_type='OPERATE'æ—¶æ‰æœ‰å€¼
      - LIKE, UNLIKE, COMMENT, SHARE, SAME_STYLE, REPORT, LARGE(ç‚¹å‡»)
    
    Args:
        behavior: è¡Œä¸ºä¿¡æ¯å­—å…¸
        item_info: ç‰©å“å…ƒæ•°æ®
    
    Returns:
        æ ¼å¼åŒ–çš„è¡Œä¸ºæè¿°
    """
    event_type = behavior.get('event_type', 'UNKNOWN')
    behavior_type = behavior.get('behavior_type', '')
    behavior_subtype = behavior.get('behavior_subtype', '')
    query_content = behavior.get('element_query_content', '')
    query_cnt = behavior.get('query_cnt', 0)
    
    sid = item_info.get('sid', '')
    title = item_info.get('title', '')
    categories = item_info.get('categories', '')
    
    # 1. ç¡®å®šè¡Œä¸ºåŠ¨è¯
    action = 'interacted with'  # é»˜è®¤
    
    if event_type == 'PRODUCE':
        # ç”Ÿäº§åœºæ™¯ï¼šbehavior_typeå’Œbehavior_subtypeéƒ½æ˜¯null
        action = 'created'
    elif behavior_type == 'OPERATE':
        # æ“ä½œè¡Œä¸ºï¼Œæ ¹æ®behavior_subtypeç»†åˆ†
        subtype_action_map = {
            'LIKE': 'liked',
            'UNLIKE': 'unliked',
            'COMMENT': 'commented on',
            'SHARE': 'shared',
            'SAME_STYLE': 'used same style for',
            'REPORT': 'reported',
            'LARGE': 'clicked'  # LARGEæ‰æ˜¯ç‚¹å‡»
        }
        action = subtype_action_map.get(behavior_subtype, 'interacted with')
    elif behavior_type == 'VIDEO_PLAY_FINISH':
        action = 'finished watching'
    elif behavior_type == 'LONG_PLAY':
        action = 'watched for a long time'
    elif behavior_type == 'SHORT_PLAY':
        action = 'browsed'
    
    # 2. æ„å»ºåŸºæœ¬æè¿°
    desc_parts = [action, 'item', sid]
    
    # 3. æ·»åŠ æ ‡é¢˜å’Œç±»åˆ«
    if title:
        desc_parts.extend([', its title is', f'"{title}"'])
    if categories:
        desc_parts.extend([', its categories are', f'"{categories}"'])
    
    # 4. æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
    context_parts = []
    
    # æœç´¢åœºæ™¯ï¼šæ·»åŠ æœç´¢è¯å’Œæœç´¢æ¬¡æ•°
    if event_type == 'SEARCH' and query_content:
        if query_cnt and int(query_cnt) > 1:
            context_parts.append(f'searched for "{query_content}" {query_cnt} times')
        else:
            context_parts.append(f'searched for "{query_content}"')
    
    # æ¨èåœºæ™¯
    elif event_type == 'RECOMMEND':
        context_parts.append('from recommendations')
    
    # ç”Ÿäº§åœºæ™¯
    elif event_type == 'PRODUCE':
        context_parts.append('created by user')
    
    # 5. ç»„åˆå®Œæ•´æè¿°
    full_desc = ' '.join(desc_parts)
    if context_parts:
        full_desc += ' (' + ', '.join(context_parts) + ')'
    
    return full_desc


def load_kling_items(items_file: Path) -> dict:
    """åŠ è½½Klingç‰©å“å…ƒæ•°æ®"""
    print(f"åŠ è½½ç‰©å“å…ƒæ•°æ®: {items_file}")
    with items_file.open("r", encoding="utf-8") as f:
        items = json.load(f)
    print(f"ç‰©å“æ•°é‡: {len(items):,}")
    return items


def load_user_behaviors(behaviors_file: Path) -> dict:
    """åŠ è½½ç”¨æˆ·è¡Œä¸ºè¯¦æƒ…"""
    print(f"åŠ è½½ç”¨æˆ·è¡Œä¸ºè¯¦æƒ…: {behaviors_file}")
    with behaviors_file.open("r", encoding="utf-8") as f:
        behaviors = json.load(f)
    print(f"ç”¨æˆ·æ•°é‡: {len(behaviors):,}")
    return behaviors


def build_rich_description(
    item_ids: list[str],
    user_id: str,
    kling_items: dict,
    user_behaviors: dict,
) -> list[str]:
    """
    æ„å»ºå¯Œæ–‡æœ¬ç”¨æˆ·ç”»åƒæè¿°
    
    Args:
        item_ids: ç‰©å“IDåˆ—è¡¨
        user_id: ç”¨æˆ·ID
        kling_items: ç‰©å“å…ƒæ•°æ®å­—å…¸
        user_behaviors: ç”¨æˆ·è¡Œä¸ºè¯¦æƒ…å­—å…¸
    
    Returns:
        ç‰©å“æè¿°åˆ—è¡¨
    """
    item_descriptions = []
    
    # è·å–è¯¥ç”¨æˆ·çš„è¡Œä¸ºåºåˆ—
    behaviors = user_behaviors.get(str(user_id), [])
    
    # åˆ›å»ºitem_idåˆ°è¡Œä¸ºçš„æ˜ å°„ï¼ˆå–æœ€åä¸€æ¬¡äº¤äº’ï¼‰
    item_to_behavior = {}
    for behavior in behaviors:
        item_id = behavior['item_id']
        item_to_behavior[item_id] = behavior  # åé¢çš„ä¼šè¦†ç›–å‰é¢çš„
    
    # ä¸ºæ¯ä¸ªitemç”Ÿæˆæè¿°
    for item_id in item_ids:
        item_info = kling_items.get(item_id)
        if not item_info:
            continue
        
        sid = item_info.get('sid')
        if not sid:
            continue
        
        # è·å–è¯¥itemçš„è¡Œä¸ºä¿¡æ¯
        behavior = item_to_behavior.get(item_id)
        
        if behavior:
            # æœ‰è¡Œä¸ºè¯¦æƒ…ï¼Œç”Ÿæˆå¯Œæ–‡æœ¬æè¿°
            desc = get_behavior_description(behavior, item_info)
        else:
            # æ²¡æœ‰è¡Œä¸ºè¯¦æƒ…ï¼Œä½¿ç”¨åŸºæœ¬æ ¼å¼
            title = item_info.get('title', '')
            categories = item_info.get('categories', '')
            desc_parts = ['interacted with item', sid]
            if title:
                desc_parts.extend([', its title is', f'"{title}"'])
            if categories:
                desc_parts.extend([', its categories are', f'"{categories}"'])
            desc = ' '.join(desc_parts)
        
        item_descriptions.append(desc)
    
    return item_descriptions


def build_dataset_entry(
    user_id: str,
    item_ids: list[str],
    tail_remove_count: int,
    kling_items: dict,
    user_behaviors: dict,
) -> dict | None:
    """
    æ„å»ºå•ä¸ªè®­ç»ƒæ ·æœ¬
    
    Args:
        user_id: ç”¨æˆ·ID
        item_ids: ç‰©å“IDåˆ—è¡¨
        tail_remove_count: å°¾éƒ¨ç§»é™¤æ•°é‡ï¼ˆtrain=2, val=1, test=0ï¼‰
        kling_items: ç‰©å“å…ƒæ•°æ®
        user_behaviors: ç”¨æˆ·è¡Œä¸ºè¯¦æƒ…
    
    Returns:
        è®­ç»ƒæ ·æœ¬å­—å…¸
    """
    # åºåˆ—é•¿åº¦æ£€æŸ¥
    if len(item_ids) <= tail_remove_count + 1:
        return None
    
    # åˆ†å‰²åºåˆ—
    candidate_ids = (
        item_ids[: len(item_ids) - tail_remove_count]
        if tail_remove_count > 0
        else item_ids
    )
    
    if len(candidate_ids) < 2:
        return None
    
    # groundtruthæ˜¯æœ€åä¸€ä¸ªç‰©å“
    groundtruth_id = candidate_ids[-1]
    description_ids = candidate_ids[:-1]
    
    if not description_ids:
        return None
    
    # è·å–groundtruthç‰©å“ä¿¡æ¯
    groundtruth_item = kling_items.get(groundtruth_id)
    if not groundtruth_item or not groundtruth_item.get('sid'):
        return None
    
    # æ„å»ºå¯Œæ–‡æœ¬æè¿°
    item_descriptions = build_rich_description(
        description_ids, user_id, kling_items, user_behaviors
    )
    
    if not item_descriptions:
        return None
    
    # ç»„è£…å®Œæ•´æè¿°
    description = "The user has " + "; ".join(item_descriptions) + ";"
    
    return {
        "user_id": user_id,
        "description": description,
        "groundtruth": groundtruth_item["sid"],
        "title": groundtruth_item.get("title", ""),
        "categories": groundtruth_item.get("categories", ""),
    }


def generate_kling_ra_data(
    sequential_file: Path,
    items_file: Path,
    behaviors_file: Path,
    output_train: Path,
    output_val: Path,
    output_test: Path,
) -> None:
    """ç”ŸæˆKling RAè®­ç»ƒæ•°æ®"""
    
    # åŠ è½½æ•°æ®
    kling_items = load_kling_items(items_file)
    user_behaviors = load_user_behaviors(behaviors_file)
    
    print(f"\nåŠ è½½ç”¨æˆ·åºåˆ—æ–‡ä»¶: {sequential_file}")
    with sequential_file.open("r", encoding="utf-8") as f:
        lines = f.readlines()
    print(f"åºåˆ—æ•°é‡: {len(lines):,}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_users': 0,
        'event_types': defaultdict(int),
        'behavior_types': defaultdict(int),
        'behavior_subtypes': defaultdict(int),
        'with_search_query': 0,
        'produce_events': 0,
    }
    
    # ç»Ÿè®¡è¡Œä¸ºç±»å‹åˆ†å¸ƒ
    print("\nç»Ÿè®¡è¡Œä¸ºç±»å‹åˆ†å¸ƒ...")
    for user_id, behaviors in user_behaviors.items():
        for behavior in behaviors:
            event_type = behavior.get('event_type', 'UNKNOWN')
            behavior_type = behavior.get('behavior_type', '') or 'NULL'
            behavior_subtype = behavior.get('behavior_subtype', '') or 'NULL'
            
            stats['event_types'][event_type] += 1
            stats['behavior_types'][behavior_type] += 1
            stats['behavior_subtypes'][behavior_subtype] += 1
            
            if event_type == 'SEARCH' and behavior.get('element_query_content'):
                stats['with_search_query'] += 1
            if event_type == 'PRODUCE':
                stats['produce_events'] += 1
    
    print("\nğŸ“ˆ äº‹ä»¶ç±»å‹åˆ†å¸ƒ:")
    for event_type in ['RECOMMEND', 'SEARCH', 'PRODUCE', 'UNKNOWN']:
        count = stats['event_types'].get(event_type, 0)
        if count > 0:
            print(f"  {event_type:12s}: {count:8,d} æ¬¡")
    
    print("\nğŸ“Š è¡Œä¸ºç±»å‹åˆ†å¸ƒ:")
    sorted_behaviors = sorted(
        stats['behavior_types'].items(), 
        key=lambda x: x[1], 
        reverse=True
    )
    for behavior_type, count in sorted_behaviors:
        print(f"  {behavior_type:20s}: {count:8,d} æ¬¡")
    
    print("\nğŸ“ æ“ä½œå­ç±»å‹åˆ†å¸ƒ (behavior_subtype):")
    sorted_subtypes = sorted(
        stats['behavior_subtypes'].items(), 
        key=lambda x: x[1], 
        reverse=True
    )
    for subtype, count in sorted_subtypes:
        print(f"  {subtype:20s}: {count:8,d} æ¬¡")
    
    print(f"\nğŸ” æœç´¢åœºæ™¯ç»Ÿè®¡:")
    search_total = stats['event_types'].get('SEARCH', 0)
    if search_total > 0:
        print(f"  æ€»æœç´¢äº‹ä»¶: {search_total:,} æ¬¡")
        print(f"  åŒ…å«æŸ¥è¯¢è¯: {stats['with_search_query']:,} æ¬¡ ({stats['with_search_query']/search_total*100:.1f}%)")
    print(f"  ç”Ÿäº§äº‹ä»¶: {stats['produce_events']:,} æ¬¡")
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    print("\nç”Ÿæˆè®­ç»ƒæ•°æ®...")
    train_rows: list[dict] = []
    val_rows: list[dict] = []
    test_rows: list[dict] = []
    
    for idx, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
        
        elements = line.split()
        if len(elements) <= 1:
            continue
        
        user_id = elements[0]
        item_ids = elements[1:]
        stats['total_users'] += 1
        
        # ç”Ÿæˆtrain/val/testæ ·æœ¬
        entry_train = build_dataset_entry(
            user_id, item_ids, 2, kling_items, user_behaviors
        )
        if entry_train:
            train_rows.append(entry_train)
        
        entry_val = build_dataset_entry(
            user_id, item_ids, 1, kling_items, user_behaviors
        )
        if entry_val:
            val_rows.append(entry_val)
        
        entry_test = build_dataset_entry(
            user_id, item_ids, 0, kling_items, user_behaviors
        )
        if entry_test:
            test_rows.append(entry_test)
        
        if (idx + 1) % 1000 == 0:
            print(f"  å·²å¤„ç† {idx + 1:,} ä¸ªç”¨æˆ·...")
    
    # åˆ›å»ºDataFrame
    print("\nåˆ›å»ºDataFrame...")
    df_train = pd.DataFrame(train_rows)
    df_val = pd.DataFrame(val_rows)
    df_test = pd.DataFrame(test_rows)
    
    print(f"\nâœ… æ•°æ®é›†å¤§å°:")
    print(f"  è®­ç»ƒé›†: {len(df_train):,} æ¡")
    print(f"  éªŒè¯é›†: {len(df_val):,} æ¡")
    print(f"  æµ‹è¯•é›†: {len(df_test):,} æ¡")
    
    # ä¿å­˜æ–‡ä»¶
    print(f"\nä¿å­˜è®­ç»ƒé›†åˆ°: {output_train}")
    df_train.to_parquet(output_train, engine="pyarrow", index=False)
    
    print(f"ä¿å­˜éªŒè¯é›†åˆ°: {output_val}")
    df_val.to_parquet(output_val, engine="pyarrow", index=False)
    
    print(f"ä¿å­˜æµ‹è¯•é›†åˆ°: {output_test}")
    df_test.to_parquet(output_test, engine="pyarrow", index=False)
    
    # é¢„è§ˆæ•°æ®
    def preview(df: pd.DataFrame, name: str) -> None:
        if len(df) == 0:
            return
        print(f"\nğŸ“‹ {name} å‰2æ¡æ ·æœ¬é¢„è§ˆ:")
        for i, (_, row) in enumerate(df.head(2).iterrows()):
            print(f"\n  æ ·æœ¬ {i+1}:")
            print(f"    ç”¨æˆ·ID: {row['user_id']}")
            print(f"    æè¿°: {row['description'][:200]}...")
            print(f"    é¢„æµ‹ç›®æ ‡: {row['groundtruth']}")
            print(f"    æ ‡é¢˜: {row['title'][:50]}...")
            print(f"    ç±»åˆ«: {row['categories']}")
    
    preview(df_train, "è®­ç»ƒé›†")
    preview(df_val, "éªŒè¯é›†")
    
    print("\nâœ¨ æ•°æ®ç”Ÿæˆå®Œæˆ!")


if __name__ == "__main__":
    # æ–‡ä»¶è·¯å¾„
    sequential_file = Path("./kling_sequential.txt")
    items_file = Path("./kling_items.json")
    behaviors_file = Path("./kling_user_behaviors.json")
    
    output_train = Path("./training_RA_train.parquet")
    output_val = Path("./training_RA_val.parquet")
    output_test = Path("./training_RA_test.parquet")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    for file in [sequential_file, items_file, behaviors_file]:
        if not file.exists():
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file}")
            exit(1)
    
    # ç”Ÿæˆæ•°æ®
    generate_kling_ra_data(
        sequential_file=sequential_file,
        items_file=items_file,
        behaviors_file=behaviors_file,
        output_train=output_train,
        output_val=output_val,
        output_test=output_test,
    )
